{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"8\">HLA-A:02*01 selection, shuffled dataset</font>\n",
    "\n",
    "Create combined df, with all structures, select on 9-mers and HLA-A:02*01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total amount of HLA: 100206\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gijst\\AppData\\Local\\Temp\\ipykernel_3756\\3782430736.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"binder\"] = df.measurement_value.apply(lambda x: int(x < 500))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total amount of HLA-A:02*01: 8356\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def load_and_preprocess_dataframe(df):\n",
    "    df = df.loc[(df.peptide.str.len() == 9) & (df.allele == \"HLA-A*02:01\")]\n",
    "    df[\"binder\"] = df.measurement_value.apply(lambda x: int(x < 500))\n",
    "    return df\n",
    "\n",
    "train_val = pd.read_csv(r'C:\\Users\\gijst\\vscode\\3DVac\\Cluster\\BA_pMHCI_human_quantitative_only_eq_shuffled_train_validation.csv')\n",
    "test = pd.read_csv(r'C:\\Users\\gijst\\vscode\\3DVac\\Cluster\\BA_pMHCI_human_quantitative_only_eq_shuffled_test.csv')\n",
    "\n",
    "hla_all = pd.concat([train_val, test], ignore_index=True)\n",
    "print(f\"Total amount of HLA: {len(hla_all)}\")\n",
    "hla_a2 = load_and_preprocess_dataframe(hla_all)\n",
    "hla_a2.to_csv(\"y:/data/hla_a_02_01.csv\", index=False)\n",
    "print(f\"Total amount of HLA-A:02*01: {len(hla_a2)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove the ID's for which the sturcture couldn't be created \n",
    "\n",
    "I've checked seperatly that the ID couldn't be created, due to the fact that the valance in some atoms is greater that permittes, this causes 133 structures to not be taken into account. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Amount of sturctures for which no sturcture could be resolved: 131\n",
      "Amount of HLA-A:02*01, with structure 8225\n"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "\n",
    "subset = hla_a2[\"ID\"].tolist()\n",
    "h5_path = r\"Y:\\data/proteins.hdf5\"\n",
    "missing_ids = []\n",
    "with h5py.File(h5_path) as h5_f:\n",
    "    modelled_ids = [modeled_id.decode(\"utf8\") for modeled_id in list(h5_f[\"ids\"][:])] # ids of modelled cases\n",
    "    if subset is not None:\n",
    "        ids = [i for i in subset if i in modelled_ids]\n",
    "        for i in subset:\n",
    "            if i not in modelled_ids:\n",
    "                missing_ids.append(i)\n",
    "print(f\"Amount of sturctures for which no sturcture could be resolved: {len(missing_ids)}\")\n",
    "\n",
    "hla_a2_filtered = hla_a2[~hla_a2['ID'].isin(missing_ids)]\n",
    "print(f\"Amount of HLA-A:02*01, with structure {len(hla_a2_filtered)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that a dataframe is created with all the structures that I've been using, I need to create dataframes, for each of the experiments. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split used for shuffled dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len of train_ids: 6015\n",
      "len of validation_ids: 1504\n",
      "len of train_ids: 6015\n",
      "len of validation_ids: 1504\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gijst\\AppData\\Local\\Temp\\ipykernel_22060\\735038987.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"binder\"] = df.measurement_value.apply(lambda x: int(x < 500))\n",
      "C:\\Users\\gijst\\AppData\\Local\\Temp\\ipykernel_22060\\735038987.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"binder\"] = df.measurement_value.apply(lambda x: int(x < 500))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def load_and_preprocess_dataframe2(df):\n",
    "    df = df.loc[(df.peptide.str.len() == 9) & (df.allele == \"HLA-A*02:01\")]\n",
    "    ids = df.ID.tolist()\n",
    "    df[\"binder\"] = df.measurement_value.apply(lambda x: int(x < 500))\n",
    "    return df, ids\n",
    "\n",
    "def split_data(df, ids):\n",
    "    training_ids, validation_ids = train_test_split(ids, test_size=0.2, stratify=df.binder, random_state=1)\n",
    "    return training_ids, validation_ids\n",
    "\n",
    "train_val_df, train_val_ids = load_and_preprocess_dataframe2(train_val)\n",
    "\n",
    "shuffled = {\"train\":split_data(train_val_df, train_val_ids)[0],\n",
    "            \"val\":split_data(train_val_df, train_val_ids)[1],\n",
    "            \"test\":load_and_preprocess_dataframe2(test)[1]}\n",
    "\n",
    "# turn dictionary into pandas dataframe, with 2 column; datatype, ID\n",
    "\n",
    "# Convert the dictionary into a list of dictionaries\n",
    "data_list = [{'datatype': key, 'ID': val} for key, values in shuffled.items() for val in values]\n",
    "\n",
    "# Create a DataFrame from the list of dictionaries\n",
    "df = pd.DataFrame(data_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that the original IDs are known I can create the dataframe with the correct IDs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8225\n"
     ]
    }
   ],
   "source": [
    "# Create a boolean mask\n",
    "mask = ~df['ID'].isin(missing_ids)\n",
    "\n",
    "# Apply the mask to the DataFrame\n",
    "df_filtered = df[mask]\n",
    "print(len(df_filtered))\n",
    "df_filtered.to_csv('Y:/data/Shuffled_dataset_IDs_datatype.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add a column, which tells if each ID is a binder or not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8225\n",
      "3\n",
      "  datatype  binders  non_binders\n",
      "0     test      404          418\n",
      "1    train     2948         2978\n",
      "2      val      735          742\n"
     ]
    }
   ],
   "source": [
    "merged_df = pd.merge(df_filtered, hla_a2, on='ID', how='inner')\n",
    "result_df = merged_df.groupby(['datatype'])['binder'].agg(binders='sum', non_binders=lambda x: len(x) - sum(x))\n",
    "print(len(merged_df))\n",
    "# Reset index to make 'datatype' a column\n",
    "result_df = result_df.reset_index()\n",
    "result_df.to_csv('Y:/data/Shuffled_dataset_binder_non_binder.csv', index=False)\n",
    "# Print the result DataFrame\n",
    "print(result_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3dvac",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
