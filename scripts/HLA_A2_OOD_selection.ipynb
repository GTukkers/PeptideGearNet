{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"8\">HLA-A:02*01 selection, OOD dataset</font>\n",
    "\n",
    "Select all the peptide from the HLA-A:02-01 dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "hla_a2 = pd.read_csv(\"y:/data/hla_a_02_01.csv\")\n",
    "peptide = hla_a2.peptide\n",
    "peptide.to_csv(\"y:/data/hla_a_02_01_peptide.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the peptide csv to cluster the data, go to https://services.healthtech.dtu.dk/services/GibbsCluster-2.0/ and submit the file with the following settings; numer of clusters = 1; use trash cluster to remove outliers = true;\n",
    "\n",
    "the outliers are used as the OOD dataset, save the file at the place you want\n",
    "\n",
    "With the returned peptide, retrace which ID belongs to it and seperate the data accordingly "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     peptide\n",
      "0  VLLNAPSEA\n",
      "1  NLDDVYSYI\n",
      "2  MTNNPPIPV\n",
      "3  NLATSIYTI\n",
      "4  GLDPTGVAV\n"
     ]
    }
   ],
   "source": [
    "gibbs_report = pd.read_csv(\"y:/data/hla_a_02_01_peptide_OOD_1_cluster.csv\")\n",
    "gibbs_report = gibbs_report.rename(columns={\"## Alignment cores for group 1\":\"peptide\"})\n",
    "print(gibbs_report.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['ID', 'allele', 'peptide', 'measurement_value',\n",
      "       'measurement_inequality', 'measurement_type', 'measurement_kind',\n",
      "       'measurement_source', 'original_allele', 'db2_folder', 'cluster',\n",
      "       'anchor_0', 'anchor_1', 'cluster_set_10', 'allele_clustering',\n",
      "       'binder'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "train_val = hla_a2[hla_a2['peptide'].isin(gibbs_report.peptide.tolist())].reset_index(drop=True)\n",
    "test = hla_a2[~hla_a2['peptide'].isin(gibbs_report.peptide.tolist())].reset_index(drop=True)\n",
    "# train_val[\"binder\"] = train_val.measurement_value.apply(lambda x: int(x < 500))\n",
    "print(train_val.columns)\n",
    "# print(train_val.head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split the train and validation accordingly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def split_data(df, ids):\n",
    "    training_ids, validation_ids = train_test_split(ids, test_size=0.2, stratify=df.binder, random_state=1)\n",
    "    return training_ids, validation_ids\n",
    "\n",
    "train_id, val_id = split_data(train_val, train_val.ID.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "OOD_1_cluster = {\"train\":train_id,\n",
    "                \"val\":val_id,\n",
    "                \"test\":test.ID.tolist()}\n",
    "\n",
    "data_list = [{'datatype': key, 'ID': val} for key, values in OOD_1_cluster.items() for val in values]\n",
    "\n",
    "# Create a DataFrame from the list of dictionaries\n",
    "df = pd.DataFrame(data_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8225\n"
     ]
    }
   ],
   "source": [
    "# Create a boolean mask\n",
    "missing_ids = pd.read_csv(\"Y:\\data\\missing_ids\\BA_pMHCI_human_quantitative_HLA_A2_missing_graph.csv\").ID\n",
    "mask = ~df['ID'].isin(missing_ids)\n",
    "\n",
    "# Apply the mask to the DataFrame\n",
    "df_filtered = df[mask]\n",
    "print(len(df_filtered))\n",
    "df_filtered.to_csv('Y:/data/OOD_1_cluster_dataset_IDs_datatype.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8225\n",
      "  datatype  binders  non_binders\n",
      "0     test       73         1680\n",
      "1    train     3214         1965\n",
      "2      val      800          493\n"
     ]
    }
   ],
   "source": [
    "merged_df = pd.merge(df_filtered, hla_a2, on='ID', how='inner')\n",
    "result_df = merged_df.groupby(['datatype'])['binder'].agg(binders='sum', non_binders=lambda x: len(x) - sum(x))\n",
    "print(len(merged_df))\n",
    "# Reset index to make 'datatype' a column\n",
    "result_df = result_df.reset_index()\n",
    "result_df.to_csv('Y:/data/OOD_1_cluster_dataset_binder_non_binder.csv', index=False)\n",
    "# Print the result DataFrame\n",
    "print(result_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3dvac",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
