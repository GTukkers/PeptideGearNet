{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"8\">HLA-A:02*01 Cross validation with Leave One Out (LOO)</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Idea is to create 5 clusters using https://services.healthtech.dtu.dk/services/GibbsCluster-2.0/, run the experiment 5 times with each time leave a different cluster out as test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "hla_a2 = pd.read_csv(\"y:/data/hla_a_02_01.csv\")\n",
    "missing_peptide = pd.read_csv(\"Y:\\data\\missing_ids\\BA_pMHCI_human_quantitative_HLA_A2_missing_graph.csv\")\n",
    "merged_df = pd.merge(hla_a2, missing_peptide, on='ID', how='inner')\n",
    "\n",
    "# Filter the rows in df1 where the ids match with df2\n",
    "filtered_hla_a2 = hla_a2[~hla_a2['ID'].isin(merged_df['ID'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8225\n",
      "Index(['ID', 'allele', 'peptide', 'measurement_value',\n",
      "       'measurement_inequality', 'measurement_type', 'measurement_kind',\n",
      "       'measurement_source', 'original_allele', 'db2_folder', 'cluster',\n",
      "       'anchor_0', 'anchor_1', 'cluster_set_10', 'allele_clustering',\n",
      "       'binder'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(len(filtered_hla_a2))\n",
    "print(filtered_hla_a2.columns)\n",
    "filtered_hla_a2.to_csv(\"y:/data/hla_a_02_01_structure_present.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "peptide_filtered = filtered_hla_a2.peptide\n",
    "peptide_filtered.to_csv(\"y:/data/hla_a_02_01_peptide_structure_present.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Peptides have now been clustered, perform additional statistics.\n",
    "\n",
    "Remember: some sequences are double, so when adding ID you should be back a the old amount of ID\n",
    "\n",
    "Create a dataframe, containing 4 columns; Cluster; ID; Sequence; Binder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6467\n"
     ]
    }
   ],
   "source": [
    "gibbs_report = pd.read_csv(\"Y:\\data\\hla_a_02_01_peptide_5_clusters.csv\", header = None)\n",
    "print(len(gibbs_report))\n",
    "cluster_label = 0\n",
    "cluster_labels = []\n",
    "\n",
    "# Iterate through each row\n",
    "for index, row in gibbs_report.iterrows():\n",
    "    if 'cores' in row[0]:\n",
    "        gibbs_report.drop(index, inplace=True)\n",
    "        cluster_label += 1\n",
    "    else:\n",
    "        cluster_labels.append(f'cluster{cluster_label}')\n",
    "\n",
    "# Create a new column with the cluster labels\n",
    "gibbs_report['cluster_label'] = cluster_labels\n",
    "\n",
    "# Create a new column with the cluster labels\n",
    "gibbs_report['cluster_label'] = cluster_labels\n",
    "gibbs_report = gibbs_report.rename(columns={0:\"peptide\"})\n",
    "desired_order = ['cluster_label', 'peptide']\n",
    "\n",
    "# Reorder the columns\n",
    "gibbs_report = gibbs_report[desired_order]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  cluster_label    peptide\n",
      "1      cluster1  TICLKNEGV\n",
      "2      cluster1  TTLSRHIFM\n",
      "3      cluster1  ELEEICHDL\n",
      "4      cluster1  MILALTVAI\n",
      "5      cluster1  YMYDFILRF\n",
      "6462\n"
     ]
    }
   ],
   "source": [
    "print(gibbs_report.head())\n",
    "print(len(gibbs_report))\n",
    "merged_df = pd.merge(filtered_hla_a2, gibbs_report, on='peptide', how='left')\n",
    "merged_df.to_csv(\"Y:/data/LOO_dataset.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8225\n"
     ]
    }
   ],
   "source": [
    "print(len(merged_df))\n",
    "binders = merged_df[['cluster_label','ID', 'peptide','binder']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               binders  non_binders\n",
      "cluster_label                      \n",
      "cluster1           606          788\n",
      "cluster2           865          960\n",
      "cluster3           651         1063\n",
      "cluster4           950          652\n",
      "cluster5          1015          675\n"
     ]
    }
   ],
   "source": [
    "result_df = merged_df.groupby(['cluster_label'])['binder'].agg(binders='sum', non_binders=lambda x: len(x) - sum(x))\n",
    "result_df.to_csv(\"Y:/data/LOO_dataset_binder_non_binder.csv\")\n",
    "print(result_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_id_binder = merged_df[['cluster_label','ID','binder']]\n",
    "cluster_id_binder.to_csv(\"Y:/data/LOO_cluster_id_binder.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3dvac",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
